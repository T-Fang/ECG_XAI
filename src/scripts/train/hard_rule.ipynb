{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(1, '../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset loaded!\n",
      "val dataset loaded!\n",
      "Using batch size:  32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.utils.train_utils import set_cuda_env, EcgDataModule, get_dummy_hparams, get_common_trainer_params, flatten_dict\n",
    "from src.basic.constants import TRAIN_LOG_PATH\n",
    "from src.models.ecg_step_module import EcgPipeline\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "SAVE_DIR = os.path.join(TRAIN_LOG_PATH, \"hard_rule/\")\n",
    "datamodule = EcgDataModule(batch_size=256, num_workers=0)\n",
    "datamodule.setup('fit')\n",
    "datamodule.hparams.batch_size = BATCH_SIZE\n",
    "print('Using batch size: ', datamodule.hparams.batch_size)\n",
    "train_dl, val_dl = datamodule.train_dataloader(), datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cuda_env(gpu_ids='7')\n",
    "\n",
    "hparams = get_dummy_hparams()\n",
    "hparams['is_using_hard_rule'] = True\n",
    "model = EcgPipeline(hparams)\n",
    "print(\"is_using_hard_rule: \", model.is_using_hard_rule)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                      monitor=\"val_metrics/auroc\",\n",
    "                                      mode=\"max\",\n",
    "                                      save_last=True,\n",
    "                                      filename=\"epoch={epoch}-step={step}-auroc={val_metrics/auroc:.7f}\",\n",
    "                                      auto_insert_metric_name=False)\n",
    "\n",
    "checkpoint_callback.CHECKPOINT_NAME_LAST = \"epoch={epoch}-step={step}-last\"\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=TensorBoardLogger(save_dir=SAVE_DIR),\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    # limit_train_batches=2,\n",
    "    # limit_val_batches=2,\n",
    "    **get_common_trainer_params())\n",
    "\n",
    "# record hyperparameters\n",
    "trainer.logger.log_hyperparams(flatten_dict(hparams))\n",
    "\n",
    "# trainer.tune(model, datamodule=datamodule)\n",
    "# if datamodule.hparams.batch_size <= 16:\n",
    "#     raise torch.cuda.OutOfMemoryError(\"Batch size <= 16, it's likely that OOM Error has occur\")\n",
    "# if len(datamodule.train_ds) % datamodule.hparams.batch_size == 1:\n",
    "#     datamodule.hparams.batch_size -= 1\n",
    "\n",
    "\n",
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
